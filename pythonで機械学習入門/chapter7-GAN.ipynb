{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import chainer\n",
    "import chainer.optimizers as Opt\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import chainer.datasets as ds\n",
    "import chainer.dataset.convert as con\n",
    "from chainer.iterators import SerialIterator as siter\n",
    "from chainer import optimizer_hooks as oph\n",
    "from chainer import Variable,Chain,config,cuda\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "import princess as ohm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 3 64 64\n"
     ]
    }
   ],
   "source": [
    "all_list=[]\n",
    "ohm.add_labeled_data(\"princess\",0,all_list)\n",
    "dataset=ds.LabeledImageDataset(all_list)\n",
    "train=ds.TransformDataset(dataset,ohm.labeled64)\n",
    "xtrain,_=con.concat_examples(train)\n",
    "Dtrain,ch,Ny,Nx=xtrain.shape\n",
    "print(Dtrain,ch,Ny,Nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Chain):\n",
    "    def __init__(self,zsize,Nx=Nx,Ny=Ny,H1=256*ch,H2=64*ch,H3=16*ch,H4=4*ch):\n",
    "        layers={}\n",
    "        layers[\"l1\"]=L.Linear(zsize,Ny//16*Nx//16*H1)\n",
    "        layers[\"bnorm1\"]=L.BatchNormalization(H1)\n",
    "        layers[\"dcnn1\"]=ohm.CBR(H1,H2,\"up\")\n",
    "        layers[\"dcnn2\"]=ohm.CBR(H2,H3,\"up\")\n",
    "        layers[\"dcnn3\"]=ohm.CBR(H3,H4,\"up\")\n",
    "        layers[\"dcnn4\"]=ohm.CBR(H4,ch,\"up\")\n",
    "        super().__init__(**layers)\n",
    "    def __call__(self,x):\n",
    "        h=self.l1(x)\n",
    "        h=F.dropout(h)\n",
    "        h=F.relu(h)\n",
    "        h=h.reshape(len(h),256*ch,4,4)\n",
    "        h=self.bnorm1(h)\n",
    "        h=self.dcnn1(h)\n",
    "        h=self.dcnn2(h)\n",
    "        h=self.dcnn3(h)\n",
    "        h=self.dcnn4(h)\n",
    "        y=F.clip(h,0.0,1.0)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Chain):\n",
    "        def __init__(self,C,ch=ch,H1=64,H2=128,H3=256,H4=512):\n",
    "            layers={}\n",
    "            layers[\"cnn1\"]=ohm.CBR(ch,H1,\"down\",bn=False,act=F.leaky_relu)\n",
    "            layers[\"cnn2\"]=ohm.CBR(H1,H2,\"down\",bn=False,act=F.leaky_relu)\n",
    "            layers[\"cnn3\"]=ohm.CBR(H2,H3,\"down\",bn=False,act=F.leaky_relu)\n",
    "            layers[\"cnn4\"]=ohm.CBR(H3,H4,\"down\",bn=False,act=F.leaky_relu)\n",
    "            layers[\"l1\"]=L.Linear(None,C)\n",
    "            super().__init__(**layers)\n",
    "        def __call__(self,x):\n",
    "            h=self.cnn1(x)\n",
    "            h=self.cnn2(h)\n",
    "            h=self.cnn3(h)\n",
    "            h=self.cnn4(h)\n",
    "            h=self.l1(h)\n",
    "            y=F.dropout(h)\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "zsize=2\n",
    "C=1\n",
    "gen=Generator(zsize)\n",
    "dis=Discriminator(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optgen=Opt.Adam(alpha=0.0005,beta1=0.5)\n",
    "optgen.setup(gen)\n",
    "#optgen.add_hook(oph.GradientClipping(0.1))\n",
    "\n",
    "optdis=Opt.Adam(alpha=0.0001,beta1=0.5)\n",
    "optdis.setup(dis)\n",
    "#optgen.add_hook(oph.GradientClipping(0.1))\n",
    "\n",
    "#cuda.get_device(0).use()\n",
    "#gen.to_gpu()\n",
    "#dis.to_gpu()\n",
    "train_gen_loss=[]\n",
    "train_dis_loss1=[]\n",
    "train_dis_loss2=[]\n",
    "result=[train_gen_loss,train_dis_loss1,train_dis_loss2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_GAN(gen,dis,optgen,optdis,data,result,T=1):\n",
    "    for time in range(T):\n",
    "        optgen.target.cleargrads()\n",
    "        ytemp=gen(data[1])\n",
    "        with chainer.using_config(\"train\",False):\n",
    "            ytrain_false=dis(ytemp)\n",
    "        loss_train_gen=0.5*F.mean((ytrain_false-1.0)**2)\n",
    "        #loss_train_gen=0.5*F.mean(F.softplus(-ytrain_false))\n",
    "        loss_train_gen.backward()\n",
    "        optgen.update()\n",
    "\n",
    "        optdis.target.cleargrads()\n",
    "        ytrain_false=dis(ytemp.data)\n",
    "        ytrain_true=dis(data[0])\n",
    "        loss1=0.5*F.mean((ytrain_false)**2)\n",
    "        loss2=0.5*F.mean((ytrain_true-1.0)**2)\n",
    "        #loss1=0.5*F.mean(F.softplus(ytrain_false))\n",
    "        #loss2=0.5*F.mean(F.softplus(-ytrain_true))\n",
    "        loss_train_dis=loss1+loss2\n",
    "        loss_train_dis.backward()\n",
    "        optdis.update()\n",
    "    #result[0].append(cuda.to_cpu(loss_train_gen.data))\n",
    "    result[0].append(loss_train_gen.data)\n",
    "    result[1].append(loss1.data)\n",
    "    result[2].append(loss2.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1000 [05:04<14:02:46, 50.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f289e26f15eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#data=cuda.to_gpu([xtrain,ztrain])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mztrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mlearning_GAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptgen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptdis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_new_epoch\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m#display.clear_dropout(wait=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-a6f9a464bbdf>\u001b[0m in \u001b[0;36mlearning_GAN\u001b[0;34m(gen, dis, optgen, optdis, data, result, T)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss_train_gen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain_false\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#loss_train_gen=0.5*F.mean(F.softplus(-ytrain_false))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss_train_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, retain_grad, enable_double_backprop, loss_scale)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \"\"\"\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'enable_backprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_double_backprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backward_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36m_backward_main\u001b[0;34m(self, retain_grad, loss_scale)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m                 _backprop_utils.backprop_step(\n\u001b[0;32m-> 1061\u001b[0;31m                     func, target_input_indexes, out_grad, in_grad)\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/_backprop_utils.py\u001b[0m in \u001b[0;36mbackprop_step\u001b[0;34m(func, target_input_indexes, grad_outputs, grad_inputs)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# otherwise, backward should be overridden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         gxs = func.backward(\n\u001b[0;32m--> 109\u001b[0;31m             target_input_indexes, grad_outputs)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_debug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/functions/normalization/batch_normalization.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, indexes, grad_outputs)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cudnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpander\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             self.mean, var, self.inv_std, self.key_axis)\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_owned_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatic_forward_optimizations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# Check for output array types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Retain all inputs by default in old-style functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_input_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/functions/normalization/batch_normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 gx = (gamma * self.inv_std)[expander] * (\n\u001b[0;32m--> 283\u001b[0;31m                     gy - (x_hat * ggamma[expander] + gbeta[expander]) * inv_m)\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 gx = cuda.elementwise(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "foldername=\"output_GAN\"\n",
    "nepoch=1000\n",
    "batch_size=10\n",
    "Nfig=3\n",
    "train_iter=siter(train,batch_size)\n",
    "with tqdm(total=nepoch) as pbar:\n",
    "    while train_iter.epoch < nepoch:\n",
    "        pbar.update(train_iter.is_new_epoch)\n",
    "        batch=train_iter.next()\n",
    "        xtrain,ttrain=con.concat_examples(batch)\n",
    "        ztrain=np.random.randn(len(xtrain)*zsize).reshape(len(xtrain),zsize).astype(np.float32)\n",
    "        #ztest=cuda.to_gpu(np.random.randn(Nfig*zsize).reshape(Nfig,zsize).astype(np.float32))\n",
    "        ztest=np.random.randn(Nfig*zsize).reshape(Nfig,zsize).astype(np.float32)\n",
    "        #data=cuda.to_gpu([xtrain,ztrain])\n",
    "        data=[xtrain,ztrain]\n",
    "        learning_GAN(gen,dis,optgen,optdis,data,result,T=5)\n",
    "        if train_iter.is_new_epoch==1 and train_iter.epoch%100==0:\n",
    "            #display.clear_dropout(wait=True)\n",
    "            #ohm.temp_image(train_iter.epoch,foldername+\"/test\",data[0],cuda_to_gpu(ztrain),ztest,gen,dis)\n",
    "            ohm.temp_image(train_iter.epoch,foldername+\"/test\",data[0],ztrain,ztest,gen,dis)\n",
    "            ohm.plot_result(result[0],\"loss function of gen\",\"step\",\"loss function\",0.0,0.6)\n",
    "            ohm.plot_result(result[1],result[2],\"loss function of dis\",\"step\",\"loss function\",0.0,0.6)\n",
    "save_model(dis,\"test_dis.h5\")\n",
    "save_model(gen,\"test_gen.h5\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bbccc4445b4e77a55c490762fc26ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='z1', max=1.0, min=-1.0, step=0.001), FloatSlider(valâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.GANview(z1=0.0, z2=0.0)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_list=[]\n",
    "ohm.add_labeled_data(\"princess\",0,all_list)\n",
    "ohm.add_labeled_data(\"white\",1,all_list)\n",
    "from ipywidgets import interact\n",
    "import chainer\n",
    "\n",
    "def GANview(z1=0.0,z2=0.0):\n",
    "    zset=np.array([[z1,z2]]).astype(np.float32)\n",
    "    with chainer.using_config(\"train\",False),chainer.using_config(\"enable_backprop\",False):\n",
    "        temp=cuda.to_cpu(gen(cuda.to_gpu(zset)).data)\n",
    "    plt.imshow(temp[0].transpose(1,2,0))\n",
    "    plt.title(\"z1={},z2={}\".format(z1,z2))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "interact(GANview,z1=(-1.0,1.0,0.001),z2=(-1.0,1.0,0.001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import chainer\n",
    "import chainer.optimizers as Opt\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import chainer.datasets as ds\n",
    "import chainer.dataset.convert as con\n",
    "from chainer.iterators import SerialIterator as siter\n",
    "from chainer import optimizer_hooks as oph\n",
    "from chainer import Variable,Chain,config,cuda\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "import princess as ohm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 3 64 64\n",
      "100 100 3 64 64\n"
     ]
    }
   ],
   "source": [
    "all_list=[]\n",
    "ohm.add_labeled_data(\"princess\",0,all_list)\n",
    "dataset=ds.LabeledImageDataset(all_list)\n",
    "dataset=ds.TransformDataset(dataset,ohm.labeled64)\n",
    "D=len(dataset)\n",
    "trainA,testA=ds.split_dataset_random(dataset,D//2)\n",
    "\n",
    "all_list=[]\n",
    "ohm.add_labeled_data(\"white\",0,all_list)\n",
    "dataset=ds.LabeledImageDataset(all_list)\n",
    "dataset=ds.TransformDataset(dataset,ohm.labeled64)\n",
    "D=len(dataset)\n",
    "trainB,testB=ds.split_dataset_random(dataset,D//2)\n",
    "\n",
    "xtrainA,_=con.concat_examples(trainA)\n",
    "xtestA,_=con.concat_examples(testA)\n",
    "xtrainB,_=con.concat_examples(trainB)\n",
    "xtestB,_=con.concat_examples(testB)\n",
    "DtrainA,ch,Ny,Nx=xtrainA.shape\n",
    "DtestA=len(xtestA)\n",
    "print(DtrainA,DtestA,ch,Ny,Nx)\n",
    "DtrainB,ch,Ny,Nx=xtrainB.shape\n",
    "DtestB=len(xtestB)\n",
    "print(DtrainB,DtestB,ch,Ny,Nx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Chain):\n",
    "    def __init__(self,ch=ch,H1=64,H2=128,H3=256,H4=512):\n",
    "        layers={}\n",
    "        layers[\"cnn1\"]=ohm.CBR(ch,H1,\"down\")\n",
    "        layers[\"cnn2\"]=ohm.CBR(H1,H2,\"down\")\n",
    "        layers[\"cnn3\"]=ohm.CBR(H2,H3,\"down\")\n",
    "        layers[\"cnn4\"]=ohm.CBR(H3,H4,\"down\")\n",
    "        layers[\"l1\"]=L.Linear(H4*4*4,H4*4*4)\n",
    "        layers[\"bnorm1\"]=L.BatchNormalization(H4*4*4)\n",
    "        layers[\"dcnn1\"]=ohm.CBR(H4,H3,\"up\")\n",
    "        layers[\"dcnn2\"]=ohm.CBR(H3,H2,\"up\")\n",
    "        layers[\"dcnn3\"]=ohm.CBR(H2,H1,\"up\")\n",
    "        layers[\"dcnn4\"]=ohm.CBR(H1,ch,\"up\")\n",
    "        super().__init__(**layers)\n",
    "    def __call__(self,x):\n",
    "        h=self.cnn1(x)\n",
    "        h=self.cnn2(h)\n",
    "        h=self.cnn3(h)\n",
    "        h=self.cnn4(h)\n",
    "        h=self.l1(h)\n",
    "        h=self.bnorm1(h)\n",
    "        h=F.relu(h)\n",
    "        h=h.reshape(len(h),512,4,4)\n",
    "        h=self.dcnn1(h)\n",
    "        h=self.dcnn2(h)\n",
    "        h=self.dcnn3(h)\n",
    "        h=self.dcnn4(h)\n",
    "        y=F.clip(h,0.0,1.0)\n",
    "        return y\n",
    "\n",
    "class Discriminator(Chain):\n",
    "    def __init__(self,C,ch=ch,H1=64,H2=128,H3=256,H4=512):\n",
    "        layers={}\n",
    "        layers[\"cnn1\"]=ohm.CBR(ch,H1,\"down\",bn=False,act=F.leaky_relu)\n",
    "        layers[\"cnn2\"]=ohm.CBR(H1,H2,\"down\",bn=False,act=F.leaky_relu)\n",
    "        layers[\"cnn3\"]=ohm.CBR(H2,H3,\"down\",bn=False,act=F.leaky_relu)\n",
    "        layers[\"cnn4\"]=ohm.CBR(H3,H4,\"down\",bn=False,act=F.leaky_relu)\n",
    "        layers[\"l1\"]=L.Linear(None,C)\n",
    "        super().__init__(**layers)\n",
    "    def __call__(self,x):\n",
    "        h=self.cnn1(x)\n",
    "        h=self.cnn2(h)\n",
    "        h=self.cnn3(h)\n",
    "        h=self.cnn4(h)\n",
    "        h=self.l1(h)\n",
    "        y=F.dropout(h)\n",
    "        return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA environment is not correctly set up\n(see https://github.com/chainer/chainer#installation).CuPy is not correctly installed.\n\nIf you are using wheel distribution (cupy-cudaXX), make sure that the version of CuPy you installed matches with the version of CUDA on your host.\nAlso, confirm that only one CuPy package is installed:\n  $ pip freeze\n\nIf you are building CuPy from source, please check your environment, uninstall CuPy and reinstall it with:\n  $ pip install cupy --no-cache-dir -vvvv\n\nCheck the Installation Guide for details:\n  https://docs-cupy.chainer.org/en/latest/install.html\n\noriginal error: libcuda.so.1: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-207b2f20e7f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moptdis_B\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0moptdis_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mgen_AtoB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mgen_BtoA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/backends/cuda.py\u001b[0m in \u001b[0;36mget_device\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    224\u001b[0m     warnings.warn('get_device is deprecated. Please use get_device_from_id or'\n\u001b[1;32m    225\u001b[0m                   ' get_device_from_array instead.', DeprecationWarning)\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/backends/cuda.py\u001b[0m in \u001b[0;36m_get_device\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_integer_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mcheck_cuda_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/backends/cuda.py\u001b[0m in \u001b[0;36mcheck_cuda_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m                '(see https://github.com/chainer/chainer#installation).')\n\u001b[1;32m     92\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_resolution_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     if (not cudnn_enabled and\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mnot\u001b[0m \u001b[0m_cudnn_disabled_by_user\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA environment is not correctly set up\n(see https://github.com/chainer/chainer#installation).CuPy is not correctly installed.\n\nIf you are using wheel distribution (cupy-cudaXX), make sure that the version of CuPy you installed matches with the version of CUDA on your host.\nAlso, confirm that only one CuPy package is installed:\n  $ pip freeze\n\nIf you are building CuPy from source, please check your environment, uninstall CuPy and reinstall it with:\n  $ pip install cupy --no-cache-dir -vvvv\n\nCheck the Installation Guide for details:\n  https://docs-cupy.chainer.org/en/latest/install.html\n\noriginal error: libcuda.so.1: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "gen_AtoB=Generator()\n",
    "gen_BtoA=Generator()\n",
    "\n",
    "C=1\n",
    "dis_A=Discriminator(C)\n",
    "dis_B=Discriminator(C)\n",
    "optgen_AtoB=Opt.Adam(alpha=0.0005,beta1=0.5)\n",
    "optgen_AtoB.setup(gen_AtoB)\n",
    "optgen_BtoA=Opt.Adam(alpha=0.0005,beta1=0.5)\n",
    "optgen_BtoA.setup(gen_BtoA)\n",
    "optdis_A=Opt.Adam(alpha=0.0001,beta1=0.5)\n",
    "optdis_A.setup(dis_A)\n",
    "optdis_B=Opt.Adam(alpha=0.0001,beta1=0.5)\n",
    "optdis_B.setup(dis_B)\n",
    "cuda.get_device(0).use()\n",
    "gen_AtoB.to_gpu()\n",
    "gen_BtoA.to_gpu()\n",
    "dis_A.to_gpu()\n",
    "dis_B.to_gpu()\n",
    "train_gen_loss_A=[]\n",
    "train_dis_loss_A1=[]\n",
    "train_dis_loss_A2=[]\n",
    "train_gen_loss_B=[]\n",
    "train_dis_loss_B1=[]\n",
    "train_dis_loss_B2=[]\n",
    "resultA=[train_gen_loss_A,train_dis_loss_A1,train_dis_loss_A2]\n",
    "resultB=[train_gen_loss_B,train_dis_loss_B1,train_dis_loss_B2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_consist(gen_BtoA,gen_AtoB,optgen_BtoA,optgen_AtoB,data,T=5):\n",
    "    a=10\n",
    "    for time in range(T):\n",
    "        optgen_BtoA.target.cleargrads()\n",
    "        optgen_AtoB.target.cleargrads()\n",
    "        ytemp1=gen_BtoA(data[1])\n",
    "        ytemp2=gen_AtoB(data[0])\n",
    "        loss_train=0.5*a*F.mean_absolute_error(ytemp1,data[1])+0.5*a*F.mean_absolute_error(ytemp2,data[0])\n",
    "        loss_train.backward()\n",
    "        result=loss_train.data\n",
    "        optgen_BtoA.update()\n",
    "        optgen_AtoB.update()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_L1(gen_BtoA,gen_AtoB,optgen_BtoA,optgen_AtoB,data,T=5):\n",
    "    a=10\n",
    "    for time in range(T):\n",
    "        optgen_BtoA.target.cleargrads()\n",
    "        optgen_AtoB.target.cleargrads()\n",
    "        ytemp1=gen_BtoA(data[0])\n",
    "        ytrain1=gen_AtoB(ytemp1)\n",
    "        ytemp2=gen_AtoB(data[1])\n",
    "        ytrain2=gen_BtoA(ytemp2)\n",
    "        loss_train=0.5*a*F.mean_absolute_error(ytrain1,data[0])+0.5*a*F.mean_absolute_error(ytrain2,data[1])\n",
    "        loss_train.backward()\n",
    "        result=loss_train.data\n",
    "        optgen_BtoA.update()\n",
    "        optgen_AtoB.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_image2(epoch,filename,dataA,dataB,gen_AtoB,gen_BtoA,dis_A,dis_B):\n",
    "    print(\"epoch\",epoch)\n",
    "    with chainer.using_config(\"train\",False),chainer.using_config(\"enable_backprop\",False):\n",
    "        xtestAB=gen_AtoB(cuda.to_gpu(dataA))\n",
    "        scoreAB=dis_B(xtestAB)\n",
    "        xtestABA=gen_BtoA(xtestAB)\n",
    "        xtestBA=gen_BtoA(cuda.to_gpu(dataB))\n",
    "        scoreBA=dis_A(xtestBA)\n",
    "        xtestBAB=gen_AtoB(xtestBA)\n",
    "    kA=np.random.randint(len(dataA))\n",
    "    kB=np.random.randint(len(dataB))\n",
    "    plt.figure(figsize=(12,9))\n",
    "    plt.subplot(3,2,1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"imageA\")\n",
    "    plt.imshow(dataA[kA,:,:,:].transpose(1,2,0))\n",
    "    plt.subplot(3,2,2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(dataB[kB,:,:,:].transpose(1,2,0))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"imageB\")\n",
    "    plt.subplot(3,2,3)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"{}\".format(cuda.to_cpu(scoreAB[kA].data)))\n",
    "    plt.imshow(cuda.to_cpu(xtestAB[kA,:,:,:].data).transpose(1,2,0))\n",
    "    plt.subplot(3,2,4)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"{}\".format(cuda.to_cpu(scoreBA[kB].data)))\n",
    "    plt.imshow(cuda.to_cpu(xtestBA[kB,:,:,:].data).transpose(1,2,0))\n",
    "    plt.subplot(3,2,5)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"A to B to A\")\n",
    "    plt.imshow(cuda.to_cpu(xtestABA[kA:,:,:].data).transpose(1,2,0))\n",
    "    plt.subplot(3,2,6)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"B to A to B\")\n",
    "    plt.imshow(cuda.to_cpu(xtestBAB[kB,:,:,:].data).transpose(1,2,0))\n",
    "    plt.savefig(filename+\"_{0:03d}.png\".format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder=\"output_princess\"\n",
    "nepoch=3000\n",
    "batch_size=10\n",
    "train_iter_A=siter(trainA,batch_size)\n",
    "train_iter_B=siter(trainB,batch_size)\n",
    "with tqdm(total=nepoch) as pbar:\n",
    "    while train_iter_A.epoch<nepoch:\n",
    "        pbar.update(train_iter_A.is_new_epoch)\n",
    "        batchA=train_iter_A.next()\n",
    "        batchB=train_iter_B.next()\n",
    "        xtrainA,_=con.concat_examples(batchA)\n",
    "        xtrainB,_=con.concat_examples(batchB)\n",
    "        dataBA=cuda.to_gpu([xtrainB,xtrainA])\n",
    "        ohm.learning_L1(gen_BtoA,gen_AtoB,optgen_BtoA,optgen_AtoB,dataBA)\n",
    "        ohm.learning_consist(gen_BtoA,gen_AtoB,optgen_BtoA,optgen_AtoB,dataBA)\n",
    "        ohm.learning_GAN(gen_AtoB,dis_B,optgen_AtoB,optdis_B,dataBA,resultB,T=5)\n",
    "        dataAB=cuda.to_gpu([xtrainA,xtrainB])\n",
    "        ohm.learning_GAN(gen_BtoA,dis_A,optgen_BtoA,optdis_A,dataAB,resultA,T=5)\n",
    "        if train_iter_A.epoch%100==0:\n",
    "            ohm.temp_image2(train_iter_A.epoch,output_folder+\"/test\",xtestA,xtestB,gen_AtoB,gen_BtoA,dis_A,dis_B)\n",
    "            ohm.plot_result(resultA[0],\"loss function A to B of gen in training\",\"step\",\"loss function\",0.0,0.6)\n",
    "            ohm.plot_result2(resultA[1],resultA[2],\"loss function A to B of dis\",\"step\",\"loss function\",0.0,0.6)\n",
    "            ohm.plot_result(resultB[0],\"loss function B to A of gen in training\",\"step\",\"loss function\",0.0,0.6)\n",
    "            ohm.plot_result2(resultB[1],resultB[2],\"loss function B to A of dis\",\"step\",\"loss function\",0.0,0.6)\n",
    "save_model(dis,\"test_dis.h6\")\n",
    "save_model(gen,\"test_gen.h6\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
